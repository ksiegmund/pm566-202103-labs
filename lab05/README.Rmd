---
title: "lab 5"
author: "ks"
date: "9/24/2021"
output: github_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Lab week 5 

```{r install-libraries}
library(data.table)
library(tidyverse)
library(leaflet)
```

### 1. Read in the met data

First read the data into a data.table.

```{r readdata, cache=TRUE}
if (!file.exists("~kims/GitHub/pm566-202103-labs/lab03/met_all.gz")) {
download.file("https://raw.githubusercontent.com/USCbiostats/data-science-data/master/02_met/met_all.gz", "met_all.gz", method="libcurl", timeout = 60)
}
dat <- data.table::fread("~kims/GitHub/pm566-202103-labs/lab03/met_all.gz")
```

### 2. Read in the stations data

```{r stations-data, cache=TRUE}
stations <- fread("ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.csv")
stations[, USAF := as.integer(USAF)]

# Dealing with NAs and 999999
stations[, USAF   := fifelse(USAF == 999999, NA_integer_, USAF)]
stations[, CTRY   := fifelse(CTRY == "", NA_character_, CTRY)]
stations[, STATE  := fifelse(STATE == "", NA_character_, STATE)]

# Selecting the three relevant columns, and keeping unique records
stations <- unique(stations[, list(USAF, CTRY, STATE)])

# Dropping NAs
stations <- stations[!is.na(USAF)]

# Removing duplicates (quick and dirty, not recommended)
stations[, n := 1:.N, by = .(USAF)]
stations <- stations[n == 1,][, n := NULL]
```

### 3. Merge the two data tables

```{r merge-data}
dat <- merge(
  # Data
  x     = dat,      
  y     = stations, 
  # List of variables to match
  by.x  = "USAFID",
  by.y  = "USAF", 
  # Which obs to keep?
  all.x = TRUE,      
  all.y = FALSE
  )
head(dat[, list(USAFID, WBAN, STATE)], n = 4)
```

### Question 1: Representative station for the US

What is the median station in terms of temperature, wind speed, and atmospheric pressure? Look for the three weather stations that best represent continental US using the quantile() function. Do these three coincide?

First, generate a representative version of each station.  We will use averages (could use medians too).
```{r collapsing-by-station}
station_averages <- dat[,.(
  temp      = mean(temp,na.rm = TRUE),
  wind.sp   = mean(wind.sp,na.rm = TRUE),
  atm.press = mean(temp,na.rm = TRUE)
), by = USAFID]
```

Now we want to find quantiles per variable.

```{r quantiles}
medians <- station_averages[,.(
  temp_50       = quantile(temp,      probs = 0.5, na.rm = TRUE),
  wind.sp_50    = quantile(wind.sp,   probs = 0.5, na.rm = TRUE),
  atm.press_50  = quantile(atm.press, probs = 0.5, na.rm = TRUE)
)]
```

Now we can find the stations that are closest to these. (hint: use the function 'which.min()')

```{r dist-to-median}
station_averages[, temp_dist := abs(temp- medians$temp_50)]
station_averages[order(temp_dist)][1]
```


Knit the document, commit your changes, and Save it on GitHub. Don’t forget to add README.md to the tree, the first time you render it.

### Question 2: Representative station per state

Just like the previous question, you are asked to identify what is the most representative, the median, station per state. This time, instead of looking at one variable at a time, look at the euclidean distance. If multiple stations show in the median, select the one located at the lowest latitude.

```{r collapsing-by-station2}
station_averages <- dat[,.(
  temp      = mean(temp,na.rm = TRUE),
  wind.sp   = mean(wind.sp,na.rm = TRUE),
  atm.press = mean(temp,na.rm = TRUE)
), by = .(USAFID,STATE)]
```

```{r quantiles2}
station_averages[, temp_50 := quantile(temp,probs = 0.5, na.rm = TRUE), by = STATE]
station_averages[, wind.sp_50 := quantile(wind.sp,probs = 0.5, na.rm = TRUE), by = STATE]  
station_averages[, atm.press_50 := quantile(atm.press,probs = 0.5, na.rm = TRUE), by = STATE]
head(station_averages)
```

```{r euclid-dist}
station_averages[, eucldist := sqrt(
   (temp - temp_50)^2 + (wind.sp - wind.sp_50)^2
)]
station_averages

```


Knit the doc and save it on GitHub.

### Question 3: In the middle?

For each state, identify what is the station that is closest to the mid-point of the state. Combining these with the stations you identified in the previous question, use leaflet() to visualize all ~100 points in the same figure, applying different colors for those identified in this question.

Knit the doc and save it on GitHub.

### Question 4: Means of means

Using the quantile() function, generate a summary table that shows the number of states included, average temperature, wind-speed, and atmospheric pressure by the variable “average temperature level,” which you’ll need to create.

Start by computing the states’ average temperature. Use that measurement to classify them according to the following criteria:

low: temp < 20
Mid: temp >= 20 and temp < 25
High: temp >= 25

```{r state-temp}
dat[, state_temp := mean(temp,na.rm = TRUE), by = STATE]
dat[, temp_cat   := fifelse(
  state_temp < 20, "low-temp",
  fifelse(state_temp < 25, "mid-temp","high-temp"))
  ]
head(dat)
```
Let's make sure we don't have NAs
```{r}
#table(dat$temp_cat,useNA=always)
```

Once you are done with that, you can compute the following:

Number of entries (records),
Number of NA entries,
Number of stations,
Number of states included, and
Mean temperature, wind-speed, and atmospheric pressure.
All by the levels described before.

```{r}
tab <- dat[, .(
    N_entries = .N,
    N_stations = length(unique(USAFID)),
    N_states = length(unique(STATE)),
    avg_temp = mean(temp, na.rm = TRUE)
)
    , by = temp_cat]

knitr::kable(tab)
```





Knit the document, commit your changes, and push them to GitHub. If you’d like, you can take this time to include the link of the issue of the week so that you let us know when you are done, e.g.,

git commit -a -m "Finalizing lab 5 https://github.com/USCbiostats/PM566/issues/23"


```{r sI}
sessionInfo()
```

